{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSrnlKPr0FOf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from tensorflow.keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import regularizers\n",
        "from keras import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zc9hvlbb5tEh"
      },
      "outputs": [],
      "source": [
        "#Reading the data from the file HIGGS_train.csv\n",
        "df = pd.read_csv('HIGGS_train.csv', low_memory=False)\n",
        "\n",
        "#Removing the string \"error\" from the dataset as it is not a float value\n",
        "df = df.replace([\"error\", \"s\"], float('nan'))\n",
        "\n",
        "# Remove double quotes from columns 8 and 21\n",
        "df[df.columns[8]] = df.iloc[:, 8].str.replace('\"', '')\n",
        "df[df.columns[21]] = df.iloc[:, 21].str.replace('\"', '')\n",
        "\n",
        "# Convert columns 8 and 21 to numeric data type (float), and replace non-numeric values with NaN\n",
        "df[df.columns[8]] = pd.to_numeric(df.iloc[:, 8], errors='coerce')\n",
        "df[df.columns[21]] = pd.to_numeric(df.iloc[:, 21], errors='coerce')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMhB9jtm58Ww",
        "outputId": "47e2f43d-11b6-4ddc-de5a-3996200e68a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 599999 entries, 0 to 599998\n",
            "Data columns (total 29 columns):\n",
            " #   Column      Non-Null Count   Dtype  \n",
            "---  ------      --------------   -----  \n",
            " 0   1.00E+00    599999 non-null  float64\n",
            " 1   8.69E-01    599999 non-null  float64\n",
            " 2   -6.35E-01   599999 non-null  float64\n",
            " 3   2.26E-01    599999 non-null  float64\n",
            " 4   3.27E-01    599999 non-null  float64\n",
            " 5   -6.90E-01   599999 non-null  float64\n",
            " 6   7.54E-01    599999 non-null  float64\n",
            " 7   -2.49E-01   599999 non-null  float64\n",
            " 8   -1.09E+00   599999 non-null  float64\n",
            " 9   0.00E+00    599999 non-null  float64\n",
            " 10  1.37E+00    599999 non-null  float64\n",
            " 11  -6.54E-01   599999 non-null  float64\n",
            " 12  9.30E-01    599999 non-null  float64\n",
            " 13  1.11E+00    599999 non-null  float64\n",
            " 14  1.14E+00    599999 non-null  float64\n",
            " 15  -1.58E+00   599999 non-null  float64\n",
            " 16  -1.05E+00   599999 non-null  float64\n",
            " 17  0.00E+00.1  599998 non-null  float64\n",
            " 18  6.58E-01    599999 non-null  float64\n",
            " 19  -1.05E-02   599999 non-null  float64\n",
            " 20  -4.58E-02   599999 non-null  float64\n",
            " 21  3.10E+00    599997 non-null  float64\n",
            " 22  1.35E+00    599999 non-null  float64\n",
            " 23  9.80E-01    599999 non-null  float64\n",
            " 24  9.78E-01    599999 non-null  float64\n",
            " 25  9.20E-01    599999 non-null  float64\n",
            " 26  7.22E-01    599999 non-null  float64\n",
            " 27  9.89E-01    599999 non-null  float64\n",
            " 28  8.77E-01    599999 non-null  float64\n",
            "dtypes: float64(29)\n",
            "memory usage: 132.8 MB\n"
          ]
        }
      ],
      "source": [
        "#Display the dataset information to check how many columns do we have, how many rows, and the data types of each column\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ha5Cc3f46Lee",
        "outputId": "49640f4a-fcde-4fe4-d2c2-2e2b417dcf93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "317571\n"
          ]
        }
      ],
      "source": [
        "#To check if the database is balanced, count the numbers of 1.00E+00 and 0.00E+00\n",
        "count = len(df[df['1.00E+00'] == 1.0]) \n",
        "\n",
        "# Print the count\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iMt5R-TBpHN"
      },
      "source": [
        "The number of 1s in the dataset turns out to be 317571, meaning that nearly half of the dataset is 0s and nearly the other half is 1s. Thus, the dataset is not imbalanced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJa-l-br8Bnd",
        "outputId": "9cecddbc-f9a3-4bff-93b8-58f9277893d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 599996 entries, 0 to 599998\n",
            "Data columns (total 29 columns):\n",
            " #   Column      Non-Null Count   Dtype  \n",
            "---  ------      --------------   -----  \n",
            " 0   1.00E+00    599996 non-null  float64\n",
            " 1   8.69E-01    599996 non-null  float64\n",
            " 2   -6.35E-01   599996 non-null  float64\n",
            " 3   2.26E-01    599996 non-null  float64\n",
            " 4   3.27E-01    599996 non-null  float64\n",
            " 5   -6.90E-01   599996 non-null  float64\n",
            " 6   7.54E-01    599996 non-null  float64\n",
            " 7   -2.49E-01   599996 non-null  float64\n",
            " 8   -1.09E+00   599996 non-null  float64\n",
            " 9   0.00E+00    599996 non-null  float64\n",
            " 10  1.37E+00    599996 non-null  float64\n",
            " 11  -6.54E-01   599996 non-null  float64\n",
            " 12  9.30E-01    599996 non-null  float64\n",
            " 13  1.11E+00    599996 non-null  float64\n",
            " 14  1.14E+00    599996 non-null  float64\n",
            " 15  -1.58E+00   599996 non-null  float64\n",
            " 16  -1.05E+00   599996 non-null  float64\n",
            " 17  0.00E+00.1  599996 non-null  float64\n",
            " 18  6.58E-01    599996 non-null  float64\n",
            " 19  -1.05E-02   599996 non-null  float64\n",
            " 20  -4.58E-02   599996 non-null  float64\n",
            " 21  3.10E+00    599996 non-null  float64\n",
            " 22  1.35E+00    599996 non-null  float64\n",
            " 23  9.80E-01    599996 non-null  float64\n",
            " 24  9.78E-01    599996 non-null  float64\n",
            " 25  9.20E-01    599996 non-null  float64\n",
            " 26  7.22E-01    599996 non-null  float64\n",
            " 27  9.89E-01    599996 non-null  float64\n",
            " 28  8.77E-01    599996 non-null  float64\n",
            "dtypes: float64(29)\n",
            "memory usage: 137.3 MB\n"
          ]
        }
      ],
      "source": [
        "dataset = df.dropna() #Drop the rows with NaN values\n",
        "dataset.info() #Display the dataset information to check how many columns do we have, how many rows, and the data types of each column after dropping the NaN values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNEDTIrQ8Q-G",
        "outputId": "20727f52-be18-42b6-d269-e4f375f6e16e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 599194 entries, 0 to 599998\n",
            "Data columns (total 29 columns):\n",
            " #   Column      Non-Null Count   Dtype  \n",
            "---  ------      --------------   -----  \n",
            " 0   1.00E+00    599194 non-null  float64\n",
            " 1   8.69E-01    599194 non-null  float64\n",
            " 2   -6.35E-01   599194 non-null  float64\n",
            " 3   2.26E-01    599194 non-null  float64\n",
            " 4   3.27E-01    599194 non-null  float64\n",
            " 5   -6.90E-01   599194 non-null  float64\n",
            " 6   7.54E-01    599194 non-null  float64\n",
            " 7   -2.49E-01   599194 non-null  float64\n",
            " 8   -1.09E+00   599194 non-null  float64\n",
            " 9   0.00E+00    599194 non-null  float64\n",
            " 10  1.37E+00    599194 non-null  float64\n",
            " 11  -6.54E-01   599194 non-null  float64\n",
            " 12  9.30E-01    599194 non-null  float64\n",
            " 13  1.11E+00    599194 non-null  float64\n",
            " 14  1.14E+00    599194 non-null  float64\n",
            " 15  -1.58E+00   599194 non-null  float64\n",
            " 16  -1.05E+00   599194 non-null  float64\n",
            " 17  0.00E+00.1  599194 non-null  float64\n",
            " 18  6.58E-01    599194 non-null  float64\n",
            " 19  -1.05E-02   599194 non-null  float64\n",
            " 20  -4.58E-02   599194 non-null  float64\n",
            " 21  3.10E+00    599194 non-null  float64\n",
            " 22  1.35E+00    599194 non-null  float64\n",
            " 23  9.80E-01    599194 non-null  float64\n",
            " 24  9.78E-01    599194 non-null  float64\n",
            " 25  9.20E-01    599194 non-null  float64\n",
            " 26  7.22E-01    599194 non-null  float64\n",
            " 27  9.89E-01    599194 non-null  float64\n",
            " 28  8.77E-01    599194 non-null  float64\n",
            "dtypes: float64(29)\n",
            "memory usage: 137.1 MB\n"
          ]
        }
      ],
      "source": [
        "clean_data = dataset.drop_duplicates() #Drop the duplicated rows\n",
        "clean_data.info() #Display the dataset information to check how many columns do we have, how many rows, and the data types of each column after dropping the duplicated rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Q8btZOKnC7GF",
        "outputId": "476d2a1c-c36f-464c-fd85-68451854dd81"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1.00E+00</th>\n",
              "      <th>8.69E-01</th>\n",
              "      <th>-6.35E-01</th>\n",
              "      <th>2.26E-01</th>\n",
              "      <th>3.27E-01</th>\n",
              "      <th>-6.90E-01</th>\n",
              "      <th>7.54E-01</th>\n",
              "      <th>-2.49E-01</th>\n",
              "      <th>-1.09E+00</th>\n",
              "      <th>0.00E+00</th>\n",
              "      <th>...</th>\n",
              "      <th>-1.05E-02</th>\n",
              "      <th>-4.58E-02</th>\n",
              "      <th>3.10E+00</th>\n",
              "      <th>1.35E+00</th>\n",
              "      <th>9.80E-01</th>\n",
              "      <th>9.78E-01</th>\n",
              "      <th>9.20E-01</th>\n",
              "      <th>7.22E-01</th>\n",
              "      <th>9.89E-01</th>\n",
              "      <th>8.77E-01</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.908</td>\n",
              "      <td>0.329</td>\n",
              "      <td>0.35900</td>\n",
              "      <td>1.500</td>\n",
              "      <td>-0.313</td>\n",
              "      <td>1.100</td>\n",
              "      <td>-0.558</td>\n",
              "      <td>-1.590</td>\n",
              "      <td>2.17</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.140</td>\n",
              "      <td>-0.000819</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.302</td>\n",
              "      <td>0.833</td>\n",
              "      <td>0.986</td>\n",
              "      <td>0.978</td>\n",
              "      <td>0.780</td>\n",
              "      <td>0.992</td>\n",
              "      <td>0.798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.799</td>\n",
              "      <td>1.470</td>\n",
              "      <td>-1.64000</td>\n",
              "      <td>0.454</td>\n",
              "      <td>0.426</td>\n",
              "      <td>1.100</td>\n",
              "      <td>1.280</td>\n",
              "      <td>1.380</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.130</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.910</td>\n",
              "      <td>1.110</td>\n",
              "      <td>0.986</td>\n",
              "      <td>0.951</td>\n",
              "      <td>0.803</td>\n",
              "      <td>0.866</td>\n",
              "      <td>0.780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.340</td>\n",
              "      <td>-0.877</td>\n",
              "      <td>0.93600</td>\n",
              "      <td>1.990</td>\n",
              "      <td>0.882</td>\n",
              "      <td>1.790</td>\n",
              "      <td>-1.650</td>\n",
              "      <td>-0.942</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.678</td>\n",
              "      <td>-1.360000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.947</td>\n",
              "      <td>1.030</td>\n",
              "      <td>0.999</td>\n",
              "      <td>0.728</td>\n",
              "      <td>0.869</td>\n",
              "      <td>1.030</td>\n",
              "      <td>0.958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.110</td>\n",
              "      <td>0.321</td>\n",
              "      <td>1.52000</td>\n",
              "      <td>0.883</td>\n",
              "      <td>-1.210</td>\n",
              "      <td>0.681</td>\n",
              "      <td>-1.070</td>\n",
              "      <td>-0.922</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.374</td>\n",
              "      <td>0.113000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.756</td>\n",
              "      <td>1.360</td>\n",
              "      <td>0.987</td>\n",
              "      <td>0.838</td>\n",
              "      <td>1.130</td>\n",
              "      <td>0.872</td>\n",
              "      <td>0.808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.600</td>\n",
              "      <td>-0.608</td>\n",
              "      <td>0.00707</td>\n",
              "      <td>1.820</td>\n",
              "      <td>-0.112</td>\n",
              "      <td>0.848</td>\n",
              "      <td>-0.566</td>\n",
              "      <td>1.580</td>\n",
              "      <td>2.17</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.654</td>\n",
              "      <td>-1.270000</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0.824</td>\n",
              "      <td>0.938</td>\n",
              "      <td>0.972</td>\n",
              "      <td>0.789</td>\n",
              "      <td>0.431</td>\n",
              "      <td>0.961</td>\n",
              "      <td>0.958</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1.00E+00  8.69E-01  -6.35E-01  2.26E-01  3.27E-01  -6.90E-01  7.54E-01   \n",
              "0       1.0     0.908      0.329   0.35900     1.500     -0.313     1.100  \\\n",
              "1       1.0     0.799      1.470  -1.64000     0.454      0.426     1.100   \n",
              "2       0.0     1.340     -0.877   0.93600     1.990      0.882     1.790   \n",
              "3       1.0     1.110      0.321   1.52000     0.883     -1.210     0.681   \n",
              "4       0.0     1.600     -0.608   0.00707     1.820     -0.112     0.848   \n",
              "\n",
              "   -2.49E-01  -1.09E+00  0.00E+00  ...  -1.05E-02  -4.58E-02  3.10E+00   \n",
              "0     -0.558     -1.590      2.17  ...     -1.140  -0.000819       0.0  \\\n",
              "1      1.280      1.380      0.00  ...      1.130   0.900000       0.0   \n",
              "2     -1.650     -0.942      0.00  ...     -0.678  -1.360000       0.0   \n",
              "3     -1.070     -0.922      0.00  ...     -0.374   0.113000       0.0   \n",
              "4     -0.566      1.580      2.17  ...     -0.654  -1.270000       3.1   \n",
              "\n",
              "   1.35E+00  9.80E-01  9.78E-01  9.20E-01  7.22E-01  9.89E-01  8.77E-01  \n",
              "0     0.302     0.833     0.986     0.978     0.780     0.992     0.798  \n",
              "1     0.910     1.110     0.986     0.951     0.803     0.866     0.780  \n",
              "2     0.947     1.030     0.999     0.728     0.869     1.030     0.958  \n",
              "3     0.756     1.360     0.987     0.838     1.130     0.872     0.808  \n",
              "4     0.824     0.938     0.972     0.789     0.431     0.961     0.958  \n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_data.head() #Display the first 5 rows of the dataset to be able to visualize its structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIHutXCVEQ3F",
        "outputId": "56e79eae-8333-4002-87c5-afdf3d18dbf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        1.00E+00  8.69E-01  -6.35E-01  2.26E-01  3.27E-01  -6.90E-01   \n",
            "0            1.0     0.908      0.329   0.35900     1.500     -0.313  \\\n",
            "1            1.0     0.799      1.470  -1.64000     0.454      0.426   \n",
            "2            0.0     1.340     -0.877   0.93600     1.990      0.882   \n",
            "3            1.0     1.110      0.321   1.52000     0.883     -1.210   \n",
            "4            0.0     1.600     -0.608   0.00707     1.820     -0.112   \n",
            "...          ...       ...        ...       ...       ...        ...   \n",
            "599994       0.0     0.680      0.223  -0.75700     0.418     -0.323   \n",
            "599995       1.0     1.610     -1.620   0.21200     0.716     -0.906   \n",
            "599996       1.0     1.070      0.364   0.34400     0.617     -1.430   \n",
            "599997       1.0     1.180     -0.173  -1.46000     0.735     -0.753   \n",
            "599998       0.0     0.771     -0.133  -1.02000     1.790     -1.650   \n",
            "\n",
            "        7.54E-01  -2.49E-01  -1.09E+00  0.00E+00  ...  -1.05E-02  -4.58E-02   \n",
            "0          1.100     -0.558    -1.5900      2.17  ...     -1.140  -0.000819  \\\n",
            "1          1.100      1.280     1.3800      0.00  ...      1.130   0.900000   \n",
            "2          1.790     -1.650    -0.9420      0.00  ...     -0.678  -1.360000   \n",
            "3          0.681     -1.070    -0.9220      0.00  ...     -0.374   0.113000   \n",
            "4          0.848     -0.566     1.5800      2.17  ...     -0.654  -1.270000   \n",
            "...          ...        ...        ...       ...  ...        ...        ...   \n",
            "599994     0.471     -0.394     0.1030      0.00  ...     -2.460   1.460000   \n",
            "599995     0.553     -0.908    -1.5600      2.17  ...      0.538  -0.490000   \n",
            "599996     0.675      0.159     0.0789      0.00  ...      0.978   1.150000   \n",
            "599997     1.020     -0.838     1.2300      0.00  ...      0.107   0.622000   \n",
            "599998     0.779      0.487     0.1900      2.17  ...     -0.314   0.667000   \n",
            "\n",
            "        3.10E+00  1.35E+00  9.80E-01  9.78E-01  9.20E-01  7.22E-01  9.89E-01   \n",
            "0            0.0       NaN     0.833     0.986     0.978     0.780     0.992  \\\n",
            "1            0.0     0.910     1.110     0.986     0.951     0.803     0.866   \n",
            "2            0.0     0.947     1.030     0.999     0.728     0.869     1.030   \n",
            "3            0.0     0.756     1.360     0.987     0.838     1.130     0.872   \n",
            "4            3.1     0.824     0.938     0.972     0.789     0.431     0.961   \n",
            "...          ...       ...       ...       ...       ...       ...       ...   \n",
            "599994       0.0     0.823     1.040     0.985     0.868     0.258     0.776   \n",
            "599995       3.1     0.810     0.643       NaN     1.020     0.626     0.773   \n",
            "599996       3.1     0.973     0.974       NaN     0.969     0.852     0.908   \n",
            "599997       0.0     0.812     1.240     0.986     0.694     0.745     0.741   \n",
            "599998       0.0     0.829     0.839     0.984     1.340     0.510     1.040   \n",
            "\n",
            "        8.77E-01  \n",
            "0          0.798  \n",
            "1          0.780  \n",
            "2          0.958  \n",
            "3          0.808  \n",
            "4          0.958  \n",
            "...          ...  \n",
            "599994     0.712  \n",
            "599995     0.701  \n",
            "599996     0.789  \n",
            "599997     0.728  \n",
            "599998     0.905  \n",
            "\n",
            "[599194 rows x 29 columns]\n",
            "Number of null values in each column after outlier replacement:\n",
            "1.00E+00           0\n",
            "8.69E-01       22914\n",
            "-6.35E-01          0\n",
            "2.26E-01           0\n",
            "3.27E-01       18255\n",
            "-6.90E-01          0\n",
            "7.54E-01       29733\n",
            "-2.49E-01       3791\n",
            "-1.09E+00          0\n",
            "0.00E+00           0\n",
            "1.37E+00       24341\n",
            "-6.54E-01       2726\n",
            "9.30E-01           0\n",
            "1.11E+00           0\n",
            "1.14E+00       19291\n",
            "-1.58E+00          0\n",
            "-1.05E+00          0\n",
            "0.00E+00.1         0\n",
            "6.58E-01       20138\n",
            "-1.05E-02          0\n",
            "-4.58E-02          0\n",
            "3.10E+00           0\n",
            "1.35E+00       86029\n",
            "9.80E-01       45416\n",
            "9.78E-01      117978\n",
            "9.20E-01       31439\n",
            "7.22E-01       36437\n",
            "9.89E-01       37228\n",
            "8.77E-01       35679\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Define a function to replace outliers with NaN using the IQR method\n",
        "def replace_outliers_iqr_with_nan(data):\n",
        "    Q1 = data.quantile(0.25)\n",
        "    Q3 = data.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return data.where((data >= lower_bound) & (data <= upper_bound), np.nan)\n",
        "\n",
        "# Replace outliers with NaN\n",
        "data_with_outliers_replaced = replace_outliers_iqr_with_nan(clean_data)\n",
        "\n",
        "# Display the dataset with outliers replaced by NaN\n",
        "print(data_with_outliers_replaced)\n",
        "\n",
        "# Count null values in each column\n",
        "null_count = data_with_outliers_replaced.isnull().sum()\n",
        "print(\"Number of null values in each column after outlier replacement:\")\n",
        "print(null_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6i4UU6JdVbD"
      },
      "outputs": [],
      "source": [
        "new_dataset = data_with_outliers_replaced.dropna() #Drop the rows with NaN values, aka drop the outliers since they have been replaced to NaN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m7lzEysdlQZ",
        "outputId": "0a5d749a-0a6a-4775-b09d-3cca88837e01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.00E+00      0\n",
              "8.69E-01      0\n",
              "-6.35E-01     0\n",
              "2.26E-01      0\n",
              "3.27E-01      0\n",
              "-6.90E-01     0\n",
              "7.54E-01      0\n",
              "-2.49E-01     0\n",
              "-1.09E+00     0\n",
              "0.00E+00      0\n",
              "1.37E+00      0\n",
              "-6.54E-01     0\n",
              "9.30E-01      0\n",
              "1.11E+00      0\n",
              "1.14E+00      0\n",
              "-1.58E+00     0\n",
              "-1.05E+00     0\n",
              "0.00E+00.1    0\n",
              "6.58E-01      0\n",
              "-1.05E-02     0\n",
              "-4.58E-02     0\n",
              "3.10E+00      0\n",
              "1.35E+00      0\n",
              "9.80E-01      0\n",
              "9.78E-01      0\n",
              "9.20E-01      0\n",
              "7.22E-01      0\n",
              "9.89E-01      0\n",
              "8.77E-01      0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_dataset.isna().sum() #Making sure the outliers have been dropped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C3qdJh5eWl7",
        "outputId": "4e0a68aa-61ab-4135-cc6c-6247fd3b3d62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 316034 entries, 1 to 599998\n",
            "Data columns (total 29 columns):\n",
            " #   Column      Non-Null Count   Dtype  \n",
            "---  ------      --------------   -----  \n",
            " 0   1.00E+00    316034 non-null  float64\n",
            " 1   8.69E-01    316034 non-null  float64\n",
            " 2   -6.35E-01   316034 non-null  float64\n",
            " 3   2.26E-01    316034 non-null  float64\n",
            " 4   3.27E-01    316034 non-null  float64\n",
            " 5   -6.90E-01   316034 non-null  float64\n",
            " 6   7.54E-01    316034 non-null  float64\n",
            " 7   -2.49E-01   316034 non-null  float64\n",
            " 8   -1.09E+00   316034 non-null  float64\n",
            " 9   0.00E+00    316034 non-null  float64\n",
            " 10  1.37E+00    316034 non-null  float64\n",
            " 11  -6.54E-01   316034 non-null  float64\n",
            " 12  9.30E-01    316034 non-null  float64\n",
            " 13  1.11E+00    316034 non-null  float64\n",
            " 14  1.14E+00    316034 non-null  float64\n",
            " 15  -1.58E+00   316034 non-null  float64\n",
            " 16  -1.05E+00   316034 non-null  float64\n",
            " 17  0.00E+00.1  316034 non-null  float64\n",
            " 18  6.58E-01    316034 non-null  float64\n",
            " 19  -1.05E-02   316034 non-null  float64\n",
            " 20  -4.58E-02   316034 non-null  float64\n",
            " 21  3.10E+00    316034 non-null  float64\n",
            " 22  1.35E+00    316034 non-null  float64\n",
            " 23  9.80E-01    316034 non-null  float64\n",
            " 24  9.78E-01    316034 non-null  float64\n",
            " 25  9.20E-01    316034 non-null  float64\n",
            " 26  7.22E-01    316034 non-null  float64\n",
            " 27  9.89E-01    316034 non-null  float64\n",
            " 28  8.77E-01    316034 non-null  float64\n",
            "dtypes: float64(29)\n",
            "memory usage: 72.3 MB\n"
          ]
        }
      ],
      "source": [
        "new_dataset.info() #Display the dataset information to check how many columns do we have, how many rows, and the data types of each column after dropping the outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8WOY3lCBpHV"
      },
      "source": [
        "After removing all the outliers, we have noticed that we lost nearly half of our dataset. Thus, dropping the outliers does not seem a right nor rational thing to do. Therefore, we have decided to keep the outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lC6Yt9qe1Bo",
        "outputId": "da425e09-6685-48dc-8c85-91fcbdaf4cd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set:\n",
            "[[0.13455839 0.58065844 0.85057471 ... 0.18326387 0.14605636 0.16060247]\n",
            " [0.08713693 0.6882716  0.97701149 ... 0.02248039 0.05770887 0.07344728]\n",
            " [0.02418494 0.73662551 0.46896552 ... 0.04057311 0.07062877 0.09578609]\n",
            " ...\n",
            " [0.00343806 0.45576132 0.39683908 ... 0.00944191 0.05143349 0.04755458]\n",
            " [0.00794309 0.77983539 0.63390805 ... 0.11074649 0.13621262 0.19614148]\n",
            " [0.26141079 0.69506173 0.26925287 ... 0.03735011 0.07407407 0.08986292]]\n",
            "404280    0.0\n",
            "87279     1.0\n",
            "354232    0.0\n",
            "367450    1.0\n",
            "161039    0.0\n",
            "         ... \n",
            "463325    1.0\n",
            "31381     0.0\n",
            "484129    0.0\n",
            "348187    0.0\n",
            "284702    1.0\n",
            "Name: 1.00E+00, Length: 479354, dtype: float64\n",
            "\n",
            "Cross-validation (validation) set:\n",
            "[[0.2033195  0.13580247 0.98850575 ... 0.0476051  0.06902916 0.06447792]\n",
            " [0.00806165 0.38909465 0.06034483 ... 0.01918414 0.1005291  0.12506346]\n",
            " [0.05844695 0.28806584 0.95114943 ... 0.07338905 0.05561708 0.05330851]\n",
            " ...\n",
            " [0.08713693 0.39547325 0.79022989 ... 0.102689   0.06582995 0.07073955]\n",
            " [0.04694724 0.24691358 0.47204023 ... 0.04057311 0.08293343 0.07700118]\n",
            " [0.1155898  0.41296296 0.79022989 ... 0.05859258 0.13252123 0.1470638 ]]\n",
            "29090     1.0\n",
            "74209     0.0\n",
            "29740     0.0\n",
            "586524    1.0\n",
            "31280     1.0\n",
            "         ... \n",
            "588221    0.0\n",
            "443681    1.0\n",
            "5147      1.0\n",
            "173009    0.0\n",
            "196076    1.0\n",
            "Name: 1.00E+00, Length: 59920, dtype: float64\n",
            "\n",
            "Testing set:\n",
            "[[0.15234143 0.1399177  0.93678161 ... 0.06914056 0.08699397 0.08512439]\n",
            " [0.46887967 0.42695473 0.775      ... 0.21109882 0.232189   0.24691149]\n",
            " [0.01885003 0.65555556 0.94827586 ... 0.02541038 0.07358189 0.10729396]\n",
            " ...\n",
            " [0.07883817 0.7962963  0.39425287 ... 0.06115632 0.10545097 0.11152479]\n",
            " [0.03995258 0.23251029 0.35431034 ... 0.11807148 0.08527132 0.08952445]\n",
            " [0.14997036 0.91769547 0.87643678 ... 0.05558933 0.1079119  0.1216788 ]]\n",
            "508781    1.0\n",
            "425395    0.0\n",
            "12775     0.0\n",
            "29585     0.0\n",
            "63851     0.0\n",
            "         ... \n",
            "597023    1.0\n",
            "46590     1.0\n",
            "227532    1.0\n",
            "204219    0.0\n",
            "302363    0.0\n",
            "Name: 1.00E+00, Length: 59920, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# The target column is the first one in the dataset\n",
        "X = clean_data.iloc[:, 1:]  # Features (all columns except the first one)\n",
        "y = clean_data.iloc[:, 0]  # Target (the first column)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into a temporary training set (which will be further divided) and a testing set\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X_normalized, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Split the temporary training set into the final training and validation sets\n",
        "X_train, X_cross_val, y_train, y_cross_val = train_test_split(X_temp, y_temp, test_size=1/9, random_state=42)\n",
        "\n",
        "# The test_size in the second split is set to 1/9 because (1/9) * 0.9 = 0.1, ensuring that the validation set is 10% of the original dataset\n",
        "\n",
        "\n",
        "# Display the resulting training set\n",
        "print(\"Training set:\")\n",
        "print(X_train)\n",
        "print(y_train)\n",
        "\n",
        "# Display the resulting cross-validation set\n",
        "print(\"\\nCross-validation (validation) set:\")\n",
        "print(X_cross_val)\n",
        "print(y_cross_val)\n",
        "\n",
        "#Display the resulting testing set\n",
        "print(\"\\nTesting set:\")\n",
        "print(X_test)\n",
        "print(y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpuBovRLBpHW"
      },
      "source": [
        "After splitting the dataset into training set (80%), cross validation set (10%) and testing set (10%), it is time to implement, train and test our models. The first model we are trying is an sklearn linear regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR2fzUHj8WyI",
        "outputId": "ca1138b2-6ced-4893-91be-80d3ec8b5a47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation set performance:\n",
            "Mean Squared Error (MSE): 0.2251016915732526\n",
            "R-squared (R²): 0.0967970033167469\n",
            "\n",
            "Testing set performance:\n",
            "Mean Squared Error (MSE): 0.22504989280098028\n",
            "R-squared (R²): 0.09614997678512138\n"
          ]
        }
      ],
      "source": [
        "# Create a Linear Regression model and fit it to the training data\n",
        "linearmodel = LinearRegression()\n",
        "linearmodel.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target values for the validation set\n",
        "y_linear_cross_val_pred = linearmodel.predict(X_cross_val)\n",
        "\n",
        "# Calculate the Mean Squared Error (MSE) and R-squared (R²) for the validation set\n",
        "mse_cross_val = mean_squared_error(y_cross_val, y_linear_cross_val_pred)\n",
        "r2_cross_val = r2_score(y_cross_val, y_linear_cross_val_pred)\n",
        "\n",
        "print(\"Validation set performance:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_cross_val}\")\n",
        "print(f\"R-squared (R²): {r2_cross_val}\")\n",
        "\n",
        "# Predict the target values for the testing set\n",
        "y_linear_test_pred = linearmodel.predict(X_test)\n",
        "\n",
        "# Calculate the Mean Squared Error (MSE) and R-squared (R²) for the testing set\n",
        "mse_test = mean_squared_error(y_test, y_linear_test_pred)\n",
        "r2_test = r2_score(y_test, y_linear_test_pred)\n",
        "\n",
        "print(\"\\nTesting set performance:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_test}\")\n",
        "print(f\"R-squared (R²): {r2_test}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kucnXCs90ir"
      },
      "source": [
        "As we can notice, the MSE is large enough to determine that linear regression is far from optimal. Moreover, the R_squared metric is close to 0, implying that the model does not provide any useful information about the target variable. After getting this result and looking back at the dataset, we can notice that our problem is a binary classification problem. Thus, our next intuition is to try logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9IGJJyN-FtR",
        "outputId": "df9a13b0-371d-4663-ea64-7c07e7897af5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation set performance:\n",
            "Accuracy: 0.6411381842456609\n",
            "\n",
            "Testing set performance:\n",
            "Accuracy: 0.6405040053404539\n"
          ]
        }
      ],
      "source": [
        "# Create a Logistic Regression model and fit it to the training data\n",
        "logisticmodel = LogisticRegression(max_iter=1000)  \n",
        "logisticmodel.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target values for the validation set\n",
        "y_logistic_cross_val_pred = logisticmodel.predict(X_cross_val)\n",
        "\n",
        "# Calculate the accuracy for the validation set\n",
        "accuracy_logistic_cross_val = accuracy_score(y_cross_val, y_logistic_cross_val_pred)\n",
        "\n",
        "print(\"Validation set performance:\")\n",
        "print(f\"Accuracy: {accuracy_logistic_cross_val}\")\n",
        "\n",
        "# Predict the target values for the testing set\n",
        "y_logistic_test_pred = logisticmodel.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy for the testing set\n",
        "accuracy_logistic_test = accuracy_score(y_test, y_logistic_test_pred)\n",
        "\n",
        "print(\"\\nTesting set performance:\")\n",
        "print(f\"Accuracy: {accuracy_logistic_test}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olP4HFkxAGPN"
      },
      "source": [
        "The following accuracy is not much high as we are aiming for an accuracy close to the mid 70s. Thus, we might want to look at more complex models to train. The next model we are trying will be a decision tree model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URMaw56WE7Et",
        "outputId": "2ab89014-af19-4e45-a892-ac3c40c6d763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation set performance:\n",
            "Accuracy: 0.6402703604806409\n",
            "\n",
            "Testing set performance:\n",
            "Accuracy: 0.6352803738317757\n"
          ]
        }
      ],
      "source": [
        "# Create a Decision Tree model and fit it to the training data\n",
        "treemodel = DecisionTreeClassifier()\n",
        "treemodel.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target values for the validation set\n",
        "y_tree_cross_val_pred = treemodel.predict(X_cross_val)\n",
        "\n",
        "# Calculate the accuracy for the validation set\n",
        "accuracy_tree_cross_val = accuracy_score(y_cross_val, y_tree_cross_val_pred)\n",
        "\n",
        "print(\"Validation set performance:\")\n",
        "print(f\"Accuracy: {accuracy_tree_cross_val}\")\n",
        "\n",
        "# Predict the target values for the testing set\n",
        "y_tree_test_pred = treemodel.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy for the testing set\n",
        "accuracy_tree_test = accuracy_score(y_test, y_tree_test_pred)\n",
        "\n",
        "print(\"\\nTesting set performance:\")\n",
        "print(f\"Accuracy: {accuracy_tree_test}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8U7KuqCGc58"
      },
      "source": [
        "The accuracy has not improved. In fact, it has depreciated. Thus trying other ways is required. The next try will consist of using XGBoost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiDBz5LgBpHY"
      },
      "source": [
        "Realizing that all the models we have tried were giving a very far of 70 accuracy. We have decided to use Grid Search in order to find the optimal parameters for our XGBOOST model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TSRL7bbIW_r",
        "outputId": "e1442ed4-85ef-4bbe-b911-f85919284650"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best parameters found:  {'subsample': 1.0, 'reg_lambda': 0.25, 'reg_alpha': 0.30000000000000004, 'n_estimators': 350, 'min_child_weight': 8, 'max_depth': 9, 'learning_rate': 0.060000000000000005, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
            "Best accuracy score found:  0.7428476682365057\n"
          ]
        }
      ],
      "source": [
        "xgb_clf = XGBClassifier(objective=\"binary:logistic\")\n",
        "\n",
        "# Define the search space for parameters\n",
        "param_dist = {\n",
        "    'n_estimators': np.arange(100, 500, 50),\n",
        "    'learning_rate': np.linspace(0.01, 0.2, 20),\n",
        "    'max_depth': np.arange(3, 10),\n",
        "    'min_child_weight': np.arange(1, 10),\n",
        "    'subsample': np.linspace(0.5, 1, 6),\n",
        "    'colsample_bytree': np.linspace(0.5, 1, 6),\n",
        "    'gamma': np.linspace(0, 0.5, 11),\n",
        "    'reg_alpha': np.linspace(0, 0.5, 11),\n",
        "    'reg_lambda': np.linspace(0, 0.5, 11)\n",
        "}\n",
        "\n",
        "# Create the RandomizedSearchCV object with a smaller number of iterations\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb_clf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=50,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    cv=5,\n",
        "    verbose=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Perform the random search\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(\"Best parameters found: \", random_search.best_params_)\n",
        "print(\"Best accuracy score found: \", random_search.best_score_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72LbGeALBpHZ"
      },
      "source": [
        "After Grid Search Algorithm nearly taking 10 hours to be done, we have decided to immediately start with a Randomized Search (as it is a little faster than Grid Search) for the next model we will be trying which is tensorflow neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1G8m-p7QBpHZ",
        "outputId": "6c50d293-709b-408c-c071-d02ea0dd23ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters found:  {'solver': 'adam', 'max_iter': 2000, 'learning_rate_init': 0.001, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (50,), 'alpha': 0.01, 'activation': 'relu'}\n",
            "Best accuracy found:  0.7115951832300221\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Define the parameter space for the randomized search\n",
        "param_dist = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100)],\n",
        "    'activation': ['relu'],\n",
        "    'solver': ['adam', 'sgd'],\n",
        "    'alpha': np.logspace(-5, -1, 5),\n",
        "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
        "    'learning_rate_init': np.logspace(-5, -1, 5),\n",
        "    'max_iter': [500, 1000, 2000]\n",
        "}\n",
        "\n",
        "# Create an MLPClassifier model\n",
        "mlp = MLPClassifier(random_state=42)\n",
        "\n",
        "# Perform the randomized search\n",
        "random_search = RandomizedSearchCV(mlp, param_distributions=param_dist, n_iter=10, cv=3, scoring='accuracy', random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and score\n",
        "print(\"Best parameters found: \", random_search.best_params_)\n",
        "print(\"Best accuracy found: \", random_search.best_score_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfEyVJ0OBpHa"
      },
      "source": [
        "After that Grid Search has outputted a 74.2 accuracy with certain hyperparameters, we have decided to plug in these parameters and tune them manually until we reach a better accuracy. After tuning the parameters the best we can, we have reached the following optimal model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WToSrD9pBpHa",
        "outputId": "0c9d47dd-2e11-4439-af83-2483ad3ebad2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set performance:\n",
            "Accuracy: 0.7751327828702795\n",
            "Validation set performance:\n",
            "Accuracy: 0.7471628838451269\n",
            "\n",
            "Testing set performance:\n",
            "Accuracy: 0.7444425901201602\n"
          ]
        }
      ],
      "source": [
        "boostmodel = XGBClassifier( eval_metric='logloss', n_estimators=1000, max_depth=14, learning_rate=0.06, min_child_weight=7, gamma=8, subsample=1, reg_lambda = 15, reg_alpha = 15)\n",
        "boostmodel.fit(X_train, y_train)\n",
        "\n",
        "y_boost_train_pred = boostmodel.predict(X_train)\n",
        "\n",
        "accuracy_boost_train = accuracy_score(y_train, y_boost_train_pred)\n",
        "\n",
        "print(\"Training set performance:\")\n",
        "print(f\"Accuracy: {accuracy_boost_train}\")\n",
        "\n",
        "# Predict the target values for the validation set\n",
        "y_boost_cross_val_pred = boostmodel.predict(X_cross_val)\n",
        "\n",
        "# Calculate the accuracy for the validation set\n",
        "accuracy_boost_cross_val = accuracy_score(y_cross_val, y_boost_cross_val_pred)\n",
        "\n",
        "print(\"Validation set performance:\")\n",
        "print(f\"Accuracy: {accuracy_boost_cross_val}\")\n",
        "\n",
        "# Predict the target values for the testing set\n",
        "y_boost_test_pred = boostmodel.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy for the testing set\n",
        "accuracy_boost_test = accuracy_score(y_test, y_boost_test_pred)\n",
        "\n",
        "print(\"\\nTesting set performance:\")\n",
        "print(f\"Accuracy: {accuracy_boost_test}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I23At0NQBpHa"
      },
      "source": [
        "After that Randomized Search has outputted a 71.1 accuracy with certain hyperparameters, we have decided to plug in these parameters and tune them manually until we reach a better accuracy. After tuning the parameters the best we can, we have reached the following optimal model:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_loss(y_true, y_pred):\n",
        "    weights = tf.constant([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0 , 3.0, 3.0, 3.0, 3.0, 3.0])  # higher weight for the second feature\n",
        "    weighted_difference = tf.math.multiply(weights, tf.math.subtract(y_true, y_pred))\n",
        "    loss = tf.math.reduce_mean(tf.math.square(weighted_difference))\n",
        "    return loss\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(900, activation='relu'),\n",
        "  tf.keras.layers.Dense(700, activation='relu'),\n",
        "  tf.keras.layers.Dense(500, activation='relu'),\n",
        "  tf.keras.layers.Dense(100, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss=custom_loss, metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_cross_val, y_cross_val))\n",
        "\n",
        "# Evaluate the model on the train, cross validation and test data\n",
        "train_loss, train_accuracy = model.evaluate(X_train, y_train)\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "cv_loss, cv_accuracy = model.evaluate(X_cross_val, y_cross_val)\n",
        "\n",
        "# Print the test accuracy\n",
        "\n",
        "print('Train accuracy:', train_accuracy)\n",
        "print('Cross Val accuracy:', cv_accuracy)\n",
        "print('Test accuracy:', test_accuracy)"
      ],
      "metadata": {
        "id": "EdYIGbC-CNc-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}